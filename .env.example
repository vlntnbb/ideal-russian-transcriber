TELEGRAM_BOT_TOKEN=123456:abc

# Telegram download limit precheck for Bot API (MB). Set to 0 to disable.
TELEGRAM_MAX_GET_FILE_MB=20

# Concurrency (parallel processing). Higher values increase CPU/RAM usage.
BOT_CONCURRENT_UPDATES=8
ASR_CONCURRENCY=2
LLM_CONCURRENCY=2

# ASR settings
WHISPER_MODEL=medium
WHISPER_BEAM_SIZE=1
WHISPER_BEST_OF=1
# WHISPER_CPU_THREADS=0
# Whisper timeout (sec). If unset, bot uses a dynamic default based on audio length.
# Set to 0 to disable timeout completely.
# WHISPER_TIMEOUT_SEC=0
GIGAAM_MODEL=v3_e2e_rnnt
# For long audio (>~25s) bot will chunk it for GigaAM; override chunk size (sec) if needed:
# GIGAAM_CHUNK_SEC=20
# Hard cancel for GigaAM: run transcription in a subprocess so it can be terminated on "Cancel".
GIGAAM_HARD_CANCEL=1

# Optional audio preprocessing in group chats:
# Reply to a voice/audio, mention the bot and add the key after the mention to enable dynamic normalization + click cleanup.
# Example: `@IdealRussianTranscribe_bot norm`
AUDIO_NORMALIZE_KEY=norm
AUDIO_NORMALIZE_FILTER=adeclick,dynaudnorm=f=500:g=11:p=0.95:m=20
DEVICE=cpu
LANGUAGE=ru

# Needed only for GigaAM long-form (> ~25s) transcription:
HF_TOKEN=
# If long-form fails (token not accepted/gated/etc), allow automatic fallback to chunking:
# GIGAAM_FALLBACK_CHUNKING=1

# Gemini (optional)
GEMINI_API_KEY=
GEMINI_MODEL=gemini-3-pro-preview
GEMINI_TEMPERATURE=1
GEMINI_TOP_P=0.95
GEMINI_MAX_OUTPUT_TOKENS=65536
GEMINI_MEDIA_RESOLUTION=default
GEMINI_THINKING_LEVEL=high
# System prompt for LLM post-processing:
# - Easiest: edit the markdown file in this repo.
GEMINI_SYSTEM_PROMPT_FILE=gemini_system_prompt.md
# - Or override via env string:
GEMINI_SYSTEM_PROMPT=

# Email authorization (optional).
# When enabled, Gemini will be available only for authorized users / whitelisted chats.
AUTH_ENABLED=0
AUTH_DOMAIN=bbooster.io
# AUTH_CODE_TTL_MIN=15
# AUTH_CODE_MIN_WORDS=6
# AUTH_CODE_MAX_WORDS=10

# SMTP settings for sending auth codes
SMTP_HOST=
SMTP_PORT=587
SMTP_USERNAME=
SMTP_PASSWORD=
SMTP_FROM=
SMTP_STARTTLS=1
# SMTP_SSL=0

# Open-source fallback LLM via Ollama (used when Gemini is not allowed/available)
OLLAMA_BASE_URL=http://127.0.0.1:11434
# Set to "auto" to pick the most capable *local* model from `ollama list`.
OLLAMA_MODEL=auto
OLLAMA_AUTO_PULL=1
# Performance tuning for strong machines:
# - "auto": enable modest autotuning on 12+ CPU cores (default)
# - "max": try to use more CPU/batch (may increase RAM usage)
OLLAMA_PERF_PROFILE=auto
# Or set explicit overrides:
# OLLAMA_NUM_THREADS=14
# OLLAMA_NUM_BATCH=512
# OLLAMA_TEMPERATURE=0.7
# OLLAMA_TOP_P=0.95
# OLLAMA_NUM_CTX=8192

# Usage analytics (local JSONL log, without transcripts/prompts)
USAGE_LOG_ENABLED=1
USAGE_LOG_PATH=usage_sessions.jsonl
