TELEGRAM_BOT_TOKEN=123456:abc

# Telegram download limit precheck for Bot API (MB). Set to 0 to disable.
TELEGRAM_MAX_GET_FILE_MB=20

# ASR settings
WHISPER_MODEL=medium
WHISPER_BEAM_SIZE=1
WHISPER_BEST_OF=1
# WHISPER_CPU_THREADS=0
# WHISPER_TIMEOUT_SEC=240
GIGAAM_MODEL=v3_e2e_rnnt
# For long audio (>~25s) bot will chunk it for GigaAM; override chunk size (sec) if needed:
# GIGAAM_CHUNK_SEC=20
DEVICE=cpu
LANGUAGE=ru

# Needed only for GigaAM long-form (> ~25s) transcription:
HF_TOKEN=
# If long-form fails (token not accepted/gated/etc), allow automatic fallback to chunking:
# GIGAAM_FALLBACK_CHUNKING=1

# Gemini (optional)
GEMINI_API_KEY=
GEMINI_MODEL=gemini-3-pro-preview
GEMINI_TEMPERATURE=1
GEMINI_TOP_P=0.95
GEMINI_MAX_OUTPUT_TOKENS=65536
GEMINI_MEDIA_RESOLUTION=default
GEMINI_THINKING_LEVEL=high
GEMINI_SYSTEM_PROMPT=

# Email authorization (optional).
# When enabled, Gemini will be available only for authorized users / whitelisted chats.
AUTH_ENABLED=0
AUTH_DOMAIN=bbooster.io
# AUTH_CODE_TTL_MIN=15
# AUTH_CODE_MIN_WORDS=6
# AUTH_CODE_MAX_WORDS=10

# SMTP settings for sending auth codes
SMTP_HOST=
SMTP_PORT=587
SMTP_USERNAME=
SMTP_PASSWORD=
SMTP_FROM=
SMTP_STARTTLS=1
# SMTP_SSL=0

# Open-source fallback LLM via Ollama (used when Gemini is not allowed/available)
OLLAMA_BASE_URL=http://127.0.0.1:11434
# Set to "auto" to pick the most capable *local* model from `ollama list`.
OLLAMA_MODEL=auto
OLLAMA_AUTO_PULL=1
# Performance tuning for strong machines:
# - "auto": enable modest autotuning on 12+ CPU cores (default)
# - "max": try to use more CPU/batch (may increase RAM usage)
OLLAMA_PERF_PROFILE=auto
# Or set explicit overrides:
# OLLAMA_NUM_THREADS=14
# OLLAMA_NUM_BATCH=512
# OLLAMA_TEMPERATURE=0.7
# OLLAMA_TOP_P=0.95
# OLLAMA_NUM_CTX=8192

# Usage analytics (local JSONL log, without transcripts/prompts)
USAGE_LOG_ENABLED=1
USAGE_LOG_PATH=usage_sessions.jsonl
